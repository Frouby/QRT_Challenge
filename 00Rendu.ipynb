{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pistes de réflexion explorées\n",
    "\n",
    "Dans cette première partie nous allons décrire plusieurs pistes qui ont été explorées dans le cadre de ce projet de Machine Learning. Certaines de ces pistes ont abouti à des résultats satisfaisants et ont servi à construire peu à peu les lignes de code présentes plus loin dans ce notebook. D'autres n'ont pas semblé assez intéressantes et n'ont pas été explorées plus en détails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de modèles spécifiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles spécifiques par secteurs\n",
    "\n",
    "Après avoir observé et lancé le notebook du benchmark, nous avons assez vite pensé à créer des modèles spécifiques pour des données se ressemblant entre elles. Notre première intuition a été de créer 12 modèles pour les 12 secteurs, en imaginant que les actions d'un même secteur ont un comportement similaire. Une soumission à 51,73% sur la base de cette idée nous a conforté dans l'idée de la creuser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles spécifiques par catégories, selon la quantité de données d'entraînement\n",
    "\n",
    "Par _catégories_ on entend ici les groupes dans lesquels les données sont classées : _Secteur_, _Groupe industriel_, etc. Cette nouvelle idée consiste en une amélioration de la précédente. Puisque des modèles spécifiques par secteurs ont donné de bons résultats, pourquoi ne pas descendre d'un cran et créer des modèles par groupes industriels ? Et pourquoi pas descendre encore aux industries ? Une nouvelle question est vite apparue : quand s'arrêter ?\n",
    "\n",
    "Pour adresser des réponses à ces questions, nous avons transformé le code précédent en y introduisant des constantes de _seuil_. Un seuil action par exemple détermine à partir de combien de données disponibles dans le set d'entaînement pour une action donnée un modèle spécifique sera créé pour cette action. Idem pour les autres catégories, en créant des modèles pour les catégories les plus petites possible.\n",
    "\n",
    "_Exemple : Si on remonte l'arborescence de l'action 2884 **(156 données)**, elle appartient à la sous-industrie 107 **(758 données)**, à l'industrie 46 **(30325 données)**, au groupe indutriel 16 **(39290 données)** et au secteur 7 **(87903 données)**. Imaginons qu'on fixe un même seuil pour toutes les catégories égal à 36000. On remonte les catégories depuis l'action jusqu'à dépasser ce seuil. Ainsi sur cet exemple, les données de l'action 2884 seront prédites avec un modèle spécifique au groupe industriel 16._\n",
    "\n",
    "Sur cette base, nous avons fait varier 2 seuils en validation croisée afin de trouver leur combinaison optimale : un seuil_secteur et un seuil_autre, commun à toutes les autres catégories. Voici un extrait des résultats de validation croisée obtenus :\n",
    "![Recherche double seuils](Recherche_double_seuil_affine_seuils_hauts.PNG)\n",
    "Remarque : les précisions obtenues sont relativement faibles comparées aux autres validations croisées effectuées. Ceci est dû à un découpage particulier pour créer les folds, sur lequel nous reviendrons un peu plus tard.\n",
    "\n",
    "Le cas indiqué par la flèche correspond à 0 modèle secteur et 1 modèle groupe industriel. Dans ce cas les données du groupe industriel 16 sont prédites avec un modèle spécifique, et toutes les autres données avec un modèl général, entraîné sur le dataset entier.\n",
    "\n",
    "Malheureusement la soumission avec ces seuils n'a pas dépassé 51,10%.\n",
    "\n",
    "La solution retenue a été un essai arbitraire avec seuil_secteur=0 (chaque secteur a un modèle spécifique associé) et seuil_autre=36000 (seul le groupe_indsutriel 16 a un modèle spécifique). Avec ces paramètres, le score de notre soumission a été de 51,82%.\n",
    "\n",
    "Ci-dessous la recherche de seuil_autre pour seuil_secteur fixé à 0 qui nous a fait retenir la valeur 36000 (il faut multiplier les valeurs en abscisse par 1,2 pour passer du KFold aux seuils réels) :\n",
    "![Recherche seuil_autre](Accuracy_per_seuil_5Folds_36000.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Toujours dans l'idée de rassembler des données qui se ressemblent pour créer des modèles spécifiques, nous avons pensé à faire du clustering sur les datasets. Notre intutition était donc de créer des modèles spécifiques en regroupant les données non pas arbitrairment mais par ressemblance. Concrètement : créer des groupes de données par clusering plutôt que de se contenter de les regrouper par secteurs.\n",
    "\n",
    "Après avoir essayé différents algorithmes de clustering nous sommes restés sur du KMeans, qui présentait des résultats satisfaisants et un temps de calcul décent. Afin d'obtenir des résultats plus rapides encore pour les validations croisées et recherches de paramètres opti, nous avons utilisé le MiniBatchKMeans. Cet algorithme est une version accélérée du KMeans, qui se fait au dépends d'un peu de précision.\n",
    "\n",
    "Voici une partie des résultats obtenus en faisant varier seuil_autre et le nombre k de clusters créés, pour seuil_secteur fixé à 0 :\n",
    "![Recherche k KMeans](Accuracy_per_k_seuil_kmeans_4Folds.PNG)\n",
    "\n",
    "La soumission de cette solution n'a pas dépassé 50,98%. Nous avons donc abandonné la piste du clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres classificateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons essayé assez tôt d'appliquer différents classificateurs aux données, avec leurs paramètres par défauts, afin de les comparer rapidement et de sélectionner les plus adaptés à notre problème.\n",
    "![Essais classificateurs](Accuracy_per_classifier_5Folds.PNG)\n",
    "Sur la base de ces essais, nous avons continué d'explorer la random forest (qui a donné tous les résultats de la partie précédente), et de regarder également du côté du KNN et de l'adaboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "\n",
    "De la même manière que nous avons fait varier divers paramètres jusque là, nous avons réalisé des validations croisées pour déterminer le k optimal. Après divers essais nous avons retenu deux valeurs de k qui ont mené à des soumissions : k=9 et k=15. Ces deux soumissions n'ont pas dépassé 50,35%. Ce sont aujourd'hui encore nos pires résultats obtenus, ce qui a poussé le KNN à rejoindre la liste des pistes abandonnées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "\n",
    "Après avoir testé plusieurs algorithmes, l'algo AdaBoost semblait prometteur. Nous avons exploré cet algortihme avec plusieurs configurations tout en modifiant les paramètres. \n",
    "Cependant il est apparu qu'il ne convenait pas à l'exercice. Nous l'avons vite abandonné avec un record d'accuracy à 51,3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau neuronal avec Keras\n",
    "\n",
    "Nous avons utilisé la bibliothèque Kéras afin d'entrainer un modèle général sur l'ensemble du train set. Après documentation, des réseaux neuronaux sont parfois utilisés pour des problèmes plus ou moins similaires. \n",
    "\n",
    "Nous avons testé plusieurs combinaisons nombre de couches/nombre de neuronnes par couche/fonction d'activation. Toujours avec un modèle séquenciel. L'accuracy sur le train set (qui est une majoration de l'accuracy sur le test set) n'a jamais dépassé 50,3% ce qui nous a conduit à abandonner la piste d'une classification via deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VariationRandom Forest : ExtraTree\n",
    "\n",
    "La documentation de sklearn recommande l'algorithme ExtraTree - similaire à RandomForest - pour éviter l'overfitting. Les premières tentatives plutôt prometteuses se sont rapprochées des résulats d'accuracy des modèles utilisant RandomForest pour des paramètres similaires. \n",
    "\n",
    "Dans ce genre d'exercice la limite entre un bon modèle et un modèle overfitté est très fine et l'enjeux et de se rapprocher de cette frontière sans la franchir. Dans le cas d'ExtraTree, certe l'overfitting n'a jamais été atteint mais il n'a pas non plus été approché, ce qui n'a pas permis de créer d'excellent modèle. La meilleur tentative avec ExtraTree s'est soldé par une accuracy plutôt honorable de 51,5%. Par la suite nous avons abandonné cet algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarque importante sur les datasets\n",
    "\n",
    "Lors de notre exploration des datasets fournis, nous avons fait quelques découvertes dont nous avons essayé de tenir compte lors de la création de nos modèles.\n",
    "\n",
    "Le plus important d'après nous est le découpage entre les sets train et test. Ce découpage n'a manifestement pas été fait de manière aléatoire ou homogène. En effet, aucune **Date** n'apparaissant dans le train n'apparaît dans le test et inversement. Nous avons donc pensé que cela pouvait expliquer les scores de précision en sortie de validation croisée très supérieurs aux scores réels de soumission (~56% contre ~51%). Puisque nous faisions des validations croisées sur des folds créés aléatoirement, on retrouvait des dates identiques dans le train et le test set, créant ainsi une sorte d'overfitting comparé aux conditions réelles de soumission. C'est pourquoi un certain nombre de validations croisées ont été réalisées par la suite avec des folds créés non pas totalement aléatoirement, mais selon les dates.\n",
    "\n",
    "Concrètement, nous avons utilisé la fonction KFold sur la liste des dates, puis récupéré les données selon leur date pour les associer au train ou au test set. En procédant ainsi, nos validations croisées donnaient des résultats bien plus proches des soumissions, autour de 51%. Nous avions ainsi plus confiance en nos résultats et avons lancé un certain nombre de recherches de paramètres optimaux dans ces conditions.\n",
    "\n",
    "Il s'est finalement avéré que les paramètres (seuil, k, ...) déterminés de cette manière donnaient des résultats décevants une fois soumis sur le site du challenge. Nous nous sommes donc rabattus sur des validations croisées aléatoires, comme au début, en comparant des valeurs que nous savions trop élevées. Nous cherchons encore aujourd'hui à expliquer ces observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques détails avant de rentrer dans le vif du sujet\n",
    "\n",
    "Avant de vous présenter notre code final, voici quelques autres détails qui ont été pensés, explorés puis testés pour aboutir à la version finale :\n",
    "\n",
    "- On utilise la totalité des RET_t et VOL_t, soit 40 features, pour l'entraînement des modèles.\n",
    "\n",
    "\n",
    "- Le nettoyage des données se fait simplement en enlevant les lignes avec au moins un RET_t ou un VOL_t supérieur à 1000. Cela ne supprime qu'une donnée du train set. Nous avons gardé ce seuil depuis le début sans le remettre en question, cela représente sûrmeent une petite piste d'amélioration.\n",
    "\n",
    "\n",
    "- Les paramètres de la random forest ont été remis en question, notamment max_depth et max_features. Nous n'avons pa trouvé mieux que ceux proposés par le benchmark.\n",
    "\n",
    "\n",
    "- Les new_features sont similaires à celles du benchmark, on n'a pas trouvé mieux qu'en considérer 5. La gestion de modèles spécifiques se fait de la manière suivante : \n",
    "    - Les new_features d'un modèle spécifique à une catégorie sont les médianes par date pour cette catégorie.\n",
    "    - Les données utilisées pour le calcul des new_features d'une catégorie ne sont pas utilisées pour les catégories supérieures (ex: s'il existe un modèle groupe_ind 16, les new_features du secteur 7 sont calculées d'après les données du secteur 7 exceptées celles du groupe_ind 16).\n",
    "    \n",
    "    \n",
    "- Un modèle spécifique est entraîné d'après toutes les données de la catégorie associée (ex: s'il existe un modèle groupe_ind 16, le modèle du secteur 7 est entraîné d'après les données du secteur 7 y compris celles du groupe_ind 16).\n",
    "\n",
    "\n",
    "- Les valeurs prédites ne sont pas centrées sur la médiane par dates comme le benchmark. AU lieu de ça on attribue directement la valeur True/False la plus probable d'après le modèle utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtention des résultats finaux\n",
    "\n",
    "Les lignes de code suivantes permettent de recréer notre soumission à 51,82%. C'est la solution que nous avons retenue et qui a fourni notre 3e score le plus élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>...</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630899</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.379412</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.110597</td>\n",
       "      <td>-0.012959</td>\n",
       "      <td>0.174521</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>0.084771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.354333</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.519391</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.356157</td>\n",
       "      <td>-0.006867</td>\n",
       "      <td>-0.308868</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.089919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.663834</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.562126</td>\n",
       "      <td>-0.036745</td>\n",
       "      <td>-0.631458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.943033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277083</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>0.139086</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.579510</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>0.802806</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY     RET_1  \\\n",
       "ID                                                                          \n",
       "0      0      2        18               5       3            44 -0.015748   \n",
       "1      0      3        43              15       6           104  0.003984   \n",
       "2      0      4        57              20       8           142  0.000440   \n",
       "3      0      8         1               1       1             2  0.031298   \n",
       "4      0     14        36              12       5            92  0.027273   \n",
       "\n",
       "    VOLUME_1     RET_2  VOLUME_2  ...  VOLUME_16    RET_17  VOLUME_17  \\\n",
       "ID                                ...                                   \n",
       "0   0.147931 -0.015504  0.179183  ...   0.630899  0.003254  -0.379412   \n",
       "1        NaN -0.090580       NaN  ...        NaN  0.003774        NaN   \n",
       "2  -0.096282 -0.058896  0.084771  ...  -0.010336 -0.017612  -0.354333   \n",
       "3  -0.429540  0.007756 -0.089919  ...   0.012105  0.033824  -0.290178   \n",
       "4  -0.847155 -0.039302 -0.943033  ...  -0.277083 -0.012659   0.139086   \n",
       "\n",
       "      RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  VOLUME_20    RET  \n",
       "ID                                                                        \n",
       "0   0.008752  -0.110597 -0.012959   0.174521 -0.002155  -0.000937   True  \n",
       "1  -0.018518        NaN -0.028777        NaN -0.034722        NaN   True  \n",
       "2  -0.006562  -0.519391 -0.012101  -0.356157 -0.006867  -0.308868  False  \n",
       "3  -0.001468  -0.663834 -0.013520  -0.562126 -0.036745  -0.631458  False  \n",
       "4   0.004237  -0.017547  0.004256   0.579510 -0.040817   0.802806  False  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('../x_train.csv', index_col='ID')\n",
    "y_train = pd.read_csv('../y_train.csv', index_col='ID')\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.read_csv('../x_test.csv', index_col='ID')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret=[f'RET_{k}' for k in range(20,0,-1)]\n",
    "vol=[f'VOLUME_{k}' for k in range(20,0,-1)]\n",
    "target = 'RET'\n",
    "categories = ['STOCK','SUB_INDUSTRY','INDUSTRY','INDUSTRY_GROUP','SECTOR']\n",
    "features_base = ret+vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_shifts = 5 #nombre de features supplémentaires\n",
    "seuil_ret = 1000\n",
    "seuil_vol = 1000\n",
    "rf_params = {\n",
    "'n_estimators': 500,\n",
    "'max_depth': 2**3,\n",
    "'random_state': 0,\n",
    "'n_jobs': -1\n",
    "}\n",
    "seuil_sector = 0\n",
    "seuil_other = 36000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = [seuil_other,seuil_other,seuil_other,seuil_other,seuil_sector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cl = train.copy()\n",
    "test_cl = test.copy()\n",
    "\n",
    "for ind_groupe in np.intersect1d(train['INDUSTRY_GROUP'].unique(),test['INDUSTRY_GROUP'].unique()):\n",
    "    for ret_t,vol_t in zip(ret,vol):\n",
    "            med_ret = train_cl[ret_t][train['INDUSTRY_GROUP']==ind_groupe].median()\n",
    "            med_vol = train_cl[vol_t][train['INDUSTRY_GROUP']==ind_groupe].median()\n",
    "\n",
    "            train_cl.loc[:,ret_t] = train_cl.loc[:,ret_t].fillna(med_ret)\n",
    "            train_cl.loc[:,vol_t] = train_cl.loc[:,vol_t].fillna(med_vol)\n",
    "            test_cl.loc[:,ret_t] = test_cl.loc[:,ret_t].fillna(med_ret)\n",
    "            test_cl.loc[:,vol_t] = test_cl.loc[:,vol_t].fillna(med_vol)\n",
    "\n",
    "train_cl  = train_cl[np.all([train_cl[col]<seuil_ret for col in ret],axis=0)]\n",
    "train_cl  = train_cl[np.all([train_cl[col]<seuil_vol for col in vol],axis=0)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_cl.loc[:,ret+vol] = scaler.fit_transform(train_cl.loc[:,ret+vol])\n",
    "test_cl.loc[:,ret+vol] = scaler.fit_transform(test_cl.loc[:,ret+vol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des groupes à conserver selon les seuils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 modèles spécifiques de STOCK vont être entraînés\n",
      "0 modèles spécifiques de SUB_INDUSTRY vont être entraînés\n",
      "0 modèles spécifiques de INDUSTRY vont être entraînés\n",
      "1 modèles spécifiques de INDUSTRY_GROUP vont être entraînés\n",
      "12 modèles spécifiques de SECTOR vont être entraînés\n"
     ]
    }
   ],
   "source": [
    "model_labels = [[] for ind_cat in range(len(categories))]\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    \n",
    "    count_group = pd.Series(collections.Counter(train_cl[cat])).sort_index()\n",
    "    for group in count_group.index:\n",
    "        \n",
    "        if count_group.loc[group]>=seuil[ind_cat]:\n",
    "            model_labels[ind_cat].append(group)\n",
    "            \n",
    "    print(f\"{len(model_labels[ind_cat])} modèles spécifiques de {cat} vont être entraînés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des new features par groupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de dataframes (vides) pour les new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train = pd.DataFrame()\n",
    "new_feat_test = pd.DataFrame()\n",
    "shifts = range(1,nb_shifts+1)\n",
    "new_features = []\n",
    "statistics = ['median']\n",
    "target_feature = 'RET'\n",
    "\n",
    "for shift in shifts:\n",
    "    for stat in statistics:\n",
    "        name = f'{target_feature}_{shift}_CATEGORIE_{stat}'\n",
    "        new_features.append(name)\n",
    "        for data in [new_feat_train,new_feat_test]:\n",
    "            data[name] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des new features pour chaque groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_cl.copy()\n",
    "test_temp = test_cl.copy()\n",
    "#Copie des datasets d'où on va peu à peu retirer les données après leur utilisation\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    for ind_group,group in enumerate(model_labels[ind_cat]):\n",
    "        \n",
    "        x_train_cl = train_temp.copy()[train_temp[cat]==group]\n",
    "        y_train_cl = train_temp[target][train_temp[cat]==group]\n",
    "        \n",
    "        x_test = test_temp.copy().loc[test_temp[cat]==group,:]\n",
    "\n",
    "        shifts = range(1,nb_shifts+1)\n",
    "        statistics = ['median']\n",
    "        gb_features = [categories[ind_cat],'DATE']\n",
    "        target_feature = 'RET'\n",
    "        \n",
    "        for shift in shifts:\n",
    "            for stat in statistics:\n",
    "                name = f'{target_feature}_{shift}_CATEGORIE_{stat}'\n",
    "                feat = f'{target_feature}_{shift}'\n",
    "                for data in [x_train_cl,x_test]:\n",
    "                    if len(data)>0:\n",
    "                        data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "                \n",
    "        new_feat_train = pd.concat([new_feat_train,x_train_cl[new_features]])\n",
    "        new_feat_test = pd.concat([new_feat_test,x_test[new_features]])\n",
    "        \n",
    "        train_temp = train_temp[train_temp[cat]!=group]\n",
    "        test_temp = test_temp[test_temp[cat]!=group] #On supprime les données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des new features pour le modèle général si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_temp,new_feat_data in zip([train_temp,test_temp],[new_feat_train,new_feat_test]):\n",
    "\n",
    "    if len(data_temp)>0:\n",
    "\n",
    "        x_data = data_temp.copy()\n",
    "\n",
    "        shifts = range(1,nb_shifts+1)\n",
    "        statistics = ['median']\n",
    "        gb_features = ['SECTOR','DATE']\n",
    "        target_feature = 'RET'\n",
    "\n",
    "        for shift in shifts:\n",
    "            for stat in statistics:\n",
    "                name = f'{target_feature}_{shift}_CATEGORIE_{stat}'\n",
    "                feat = f'{target_feature}_{shift}'\n",
    "                x_data[name] = x_data.groupby(gb_features)[feat].transform(stat)\n",
    "\n",
    "        new_feat_data = pd.concat([new_feat_data,x_data[new_features]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout des new features aux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train = new_feat_train.loc[train_cl.index]\n",
    "new_feat_test = new_feat_test.loc[test_cl.index] #Réindexage pour associer les new features aux bonnes lignes\n",
    "\n",
    "train_cl[new_features] = new_feat_train\n",
    "test_cl[new_features] = new_feat_test #Ajout des colonnes new features au dataset d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles par groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle INDUSTRY_GROUP 16 entraîné : 39290 données\n",
      "Modèle SECTOR 0 entraîné : 6304 données\n",
      "Modèle SECTOR 1 entraîné : 21264 données\n",
      "Modèle SECTOR 2 entraîné : 18967 données\n",
      "Modèle SECTOR 3 entraîné : 55473 données\n",
      "Modèle SECTOR 4 entraîné : 63519 données\n",
      "Modèle SECTOR 5 entraîné : 17295 données\n",
      "Modèle SECTOR 6 entraîné : 55122 données\n",
      "Modèle SECTOR 7 entraîné : 87903 données\n",
      "Modèle SECTOR 8 entraîné : 70843 données\n",
      "Modèle SECTOR 9 entraîné : 5555 données\n",
      "Modèle SECTOR 10 entraîné : 13295 données\n",
      "Modèle SECTOR 11 entraîné : 3054 données\n"
     ]
    }
   ],
   "source": [
    "models = [{} for ind_cat in range(len(categories)+1)]\n",
    "features = features_base + new_features\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    for ind_group,group in enumerate(model_labels[ind_cat]):\n",
    "        \n",
    "        x_train_cl = train_cl.copy()[train_cl[cat]==group]\n",
    "        y_train_cl = train_cl[target][train_cl[cat]==group]\n",
    "\n",
    "        model = RandomForestClassifier(**rf_params)\n",
    "        model.fit(x_train_cl[features], y_train_cl)\n",
    "        models[ind_cat][group] = model\n",
    "\n",
    "        print(f\"Modèle {cat} {group} entraîné : {len(x_train_cl)} données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle général si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_temp)>0:\n",
    "    \n",
    "    x_train_cl = train_cl.copy()\n",
    "    y_train_cl = train_cl[target]\n",
    "\n",
    "    model = RandomForestClassifier(**rf_params)\n",
    "    model.fit(x_train_cl[features], y_train_cl)\n",
    "    models[5]['general'] = model\n",
    "    print(f\"Modèle général entraîné : {len(x_train_cl)} données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions par groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17939 données prédites avec le modèle INDUSTRY_GROUP 16\n",
      "2177 données prédites avec le modèle SECTOR 0\n",
      "11844 données prédites avec le modèle SECTOR 1\n",
      "9176 données prédites avec le modèle SECTOR 2\n",
      "27312 données prédites avec le modèle SECTOR 3\n",
      "27951 données prédites avec le modèle SECTOR 4\n",
      "7977 données prédites avec le modèle SECTOR 5\n",
      "27706 données prédites avec le modèle SECTOR 6\n",
      "23248 données prédites avec le modèle SECTOR 7\n",
      "30092 données prédites avec le modèle SECTOR 8\n",
      "3358 données prédites avec le modèle SECTOR 9\n",
      "5733 données prédites avec le modèle SECTOR 10\n",
      "3916 données prédites avec le modèle SECTOR 11\n"
     ]
    }
   ],
   "source": [
    "test_temp = test_cl.copy()\n",
    "y_pred = pd.Series()\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    for ind_group,group in enumerate(model_labels[ind_cat]):\n",
    "        \n",
    "        x_test = test_temp.copy().loc[test_temp[cat]==group,:]\n",
    "        if len(x_test)>0:\n",
    "            \n",
    "            index = x_test.index\n",
    "            model = models[ind_cat][group]\n",
    "            y_pred = pd.concat([y_pred,pd.Series(model.predict(x_test[features]),index=x_test.index)])\n",
    "            print(f\"{len(x_test)} données prédites avec le modèle {cat} {group}\")\n",
    "\n",
    "            test_temp = test_temp[test_temp[cat]!=group] #On supprime les données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions avec le modèle général si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(test_temp)>0:\n",
    "    x_test = test_temp.copy()\n",
    "    index = x_test.index\n",
    "    model = models[5]['general']\n",
    "    \n",
    "    y_pred = pd.concat([y_pred,pd.Series(model.predict(x_test[features]),index=x_test.index)])\n",
    "    print(f\"{len(x_test)} données prédites avec le modèle général\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données prédites pour soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred[test_cl.index]\n",
    "y_pred.name = target\n",
    "# y_pred.to_csv('./nom_submit.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
