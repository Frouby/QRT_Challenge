{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pistes de réflexion explorées\n",
    "\n",
    "Dans cette première partie nous allons décrire plusieurs pistes qui ont été explorées dans le cadre de ce projet de Machine Learning. Certaines de ces pistes ont abouti à des résultats satisfaisants et ont servi à construire peu à peu les lignes de code présentes plus loin dans ce notebook. D'autres n'ont pas semblé assez intéressantes et n'ont pas été explorées plus en détails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles spécifiques par secteurs\n",
    "\n",
    "Après avoir observé et lancé le notebook du benchmark, nous avons assez vite pensé à créer des modèles spécifiques pour des données se ressemblant entre elles. Notre première intuition a été de créer 12 modèles pour les 12 secteurs, en imaginant que les actions d'un même secteur ont un comportement similaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles spécifiques par catégories, selon la quantité de données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques en vrac sur les datasets\n",
    "\n",
    "- Découpage train/test : dates blabla\n",
    "- Industry ou je sais plus quoi inexistante en train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres classificateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtention des résultats finaux\n",
    "\n",
    "Les lignes de code suivantes permettent de recréer notre soumission à 51,82%. C'est la solution que nous avons retenue et qui a fourni notre 3e score le plus élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>...</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630899</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.379412</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.110597</td>\n",
       "      <td>-0.012959</td>\n",
       "      <td>0.174521</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>0.084771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.354333</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.519391</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.356157</td>\n",
       "      <td>-0.006867</td>\n",
       "      <td>-0.308868</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.089919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.663834</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.562126</td>\n",
       "      <td>-0.036745</td>\n",
       "      <td>-0.631458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.943033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277083</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>0.139086</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.579510</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>0.802806</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY     RET_1  \\\n",
       "ID                                                                          \n",
       "0      0      2        18               5       3            44 -0.015748   \n",
       "1      0      3        43              15       6           104  0.003984   \n",
       "2      0      4        57              20       8           142  0.000440   \n",
       "3      0      8         1               1       1             2  0.031298   \n",
       "4      0     14        36              12       5            92  0.027273   \n",
       "\n",
       "    VOLUME_1     RET_2  VOLUME_2  ...  VOLUME_16    RET_17  VOLUME_17  \\\n",
       "ID                                ...                                   \n",
       "0   0.147931 -0.015504  0.179183  ...   0.630899  0.003254  -0.379412   \n",
       "1        NaN -0.090580       NaN  ...        NaN  0.003774        NaN   \n",
       "2  -0.096282 -0.058896  0.084771  ...  -0.010336 -0.017612  -0.354333   \n",
       "3  -0.429540  0.007756 -0.089919  ...   0.012105  0.033824  -0.290178   \n",
       "4  -0.847155 -0.039302 -0.943033  ...  -0.277083 -0.012659   0.139086   \n",
       "\n",
       "      RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  VOLUME_20    RET  \n",
       "ID                                                                        \n",
       "0   0.008752  -0.110597 -0.012959   0.174521 -0.002155  -0.000937   True  \n",
       "1  -0.018518        NaN -0.028777        NaN -0.034722        NaN   True  \n",
       "2  -0.006562  -0.519391 -0.012101  -0.356157 -0.006867  -0.308868  False  \n",
       "3  -0.001468  -0.663834 -0.013520  -0.562126 -0.036745  -0.631458  False  \n",
       "4   0.004237  -0.017547  0.004256   0.579510 -0.040817   0.802806  False  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('../x_train.csv', index_col='ID')\n",
    "y_train = pd.read_csv('../y_train.csv', index_col='ID')\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.read_csv('../x_test.csv', index_col='ID')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret=[f'RET_{k}' for k in range(20,0,-1)]\n",
    "vol=[f'VOLUME_{k}' for k in range(20,0,-1)]\n",
    "target = 'RET'\n",
    "categories = ['STOCK','SUB_INDUSTRY','INDUSTRY','INDUSTRY_GROUP','SECTOR']\n",
    "features_base = ret+vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_shifts = 5 #nombre de features supplémentaires\n",
    "seuil_ret = 1000\n",
    "seuil_vol = 1000\n",
    "rf_params = {\n",
    "'n_estimators': 500,\n",
    "'max_depth': 2**3,\n",
    "'random_state': 0,\n",
    "'n_jobs': -1\n",
    "}\n",
    "seuil_sector = 0\n",
    "seuil_other = 36000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = [seuil_other,seuil_other,seuil_other,seuil_other,seuil_sector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cl = train.copy()\n",
    "test_cl = test.copy()\n",
    "\n",
    "for ind_groupe in np.intersect1d(train['INDUSTRY_GROUP'].unique(),test['INDUSTRY_GROUP'].unique()):\n",
    "    for ret_t,vol_t in zip(ret,vol):\n",
    "            med_ret = train_cl[ret_t][train['INDUSTRY_GROUP']==ind_groupe].median()\n",
    "            med_vol = train_cl[vol_t][train['INDUSTRY_GROUP']==ind_groupe].median()\n",
    "\n",
    "            train_cl.loc[:,ret_t] = train_cl.loc[:,ret_t].fillna(med_ret)\n",
    "            train_cl.loc[:,vol_t] = train_cl.loc[:,vol_t].fillna(med_vol)\n",
    "            test_cl.loc[:,ret_t] = test_cl.loc[:,ret_t].fillna(med_ret)\n",
    "            test_cl.loc[:,vol_t] = test_cl.loc[:,vol_t].fillna(med_vol)\n",
    "\n",
    "train_cl  = train_cl[np.all([train_cl[col]<seuil_ret for col in ret],axis=0)]\n",
    "train_cl  = train_cl[np.all([train_cl[col]<seuil_vol for col in vol],axis=0)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_cl.loc[:,ret+vol] = scaler.fit_transform(train_cl.loc[:,ret+vol])\n",
    "test_cl.loc[:,ret+vol] = scaler.fit_transform(test_cl.loc[:,ret+vol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des groupes à conserver selon les seuils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 modèles spécifiques de STOCK vont être entraînés\n",
      "0 modèles spécifiques de SUB_INDUSTRY vont être entraînés\n",
      "0 modèles spécifiques de INDUSTRY vont être entraînés\n",
      "1 modèles spécifiques de INDUSTRY_GROUP vont être entraînés\n",
      "12 modèles spécifiques de SECTOR vont être entraînés\n"
     ]
    }
   ],
   "source": [
    "model_labels = [[] for ind_cat in range(len(categories))]\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    \n",
    "    count_group = pd.Series(collections.Counter(train_cl[cat])).sort_index()\n",
    "    for group in count_group.index:\n",
    "        \n",
    "        if count_group.loc[group]>=seuil[ind_cat]:\n",
    "            model_labels[ind_cat].append(group)\n",
    "            \n",
    "    print(f\"{len(model_labels[ind_cat])} modèles spécifiques de {cat} vont être entraînés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des new features par groupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de dataframes (vides) pour les new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train = pd.DataFrame()\n",
    "new_feat_test = pd.DataFrame()\n",
    "shifts = range(1,nb_shifts+1)\n",
    "new_features = []\n",
    "statistics = ['median']\n",
    "target_feature = 'RET'\n",
    "\n",
    "for shift in shifts:\n",
    "    for stat in statistics:\n",
    "        name = f'{target_feature}_{shift}_CATEGORIE_{stat}'\n",
    "        new_features.append(name)\n",
    "        for data in [new_feat_train,new_feat_test]:\n",
    "            data[name] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des new features pour chaque groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train_cl.copy()\n",
    "test_temp = test_cl.copy()\n",
    "#Copie des datasets d'où on va peu à peu retirer les données après leur utilisation\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    for ind_group,group in enumerate(model_labels[ind_cat]):\n",
    "        \n",
    "        x_train_cl = train_temp.copy()[train_temp[cat]==group]\n",
    "        y_train_cl = train_temp[target][train_temp[cat]==group]\n",
    "        \n",
    "        x_test = test_temp.copy().loc[test_temp[cat]==group,:]\n",
    "\n",
    "        shifts = range(1,nb_shifts+1)\n",
    "        statistics = ['median']\n",
    "        gb_features = [categories[ind_cat],'DATE']\n",
    "        target_feature = 'RET'\n",
    "        \n",
    "        for shift in shifts:\n",
    "            for stat in statistics:\n",
    "                name = f'{target_feature}_{shift}_CATEGORIE_{stat}'\n",
    "                feat = f'{target_feature}_{shift}'\n",
    "                for data in [x_train_cl,x_test]:\n",
    "                    if len(data)>0:\n",
    "                        data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "                \n",
    "        new_feat_train = pd.concat([new_feat_train,x_train_cl[new_features]])\n",
    "        new_feat_test = pd.concat([new_feat_test,x_test[new_features]])\n",
    "        \n",
    "        train_temp = train_temp[train_temp[cat]!=group]\n",
    "        test_temp = test_temp[test_temp[cat]!=group] #On supprime les données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des new features pour le modèle général si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_temp,new_feat_data in zip([train_temp,test_temp],[new_feat_train,new_feat_test]):\n",
    "\n",
    "    if len(data_temp)>0:\n",
    "\n",
    "        x_data = data_temp.copy()\n",
    "\n",
    "        shifts = range(1,nb_shifts+1)\n",
    "        statistics = ['median']\n",
    "        gb_features = ['SECTOR','DATE']\n",
    "        target_feature = 'RET'\n",
    "\n",
    "        for shift in shifts:\n",
    "            for stat in statistics:\n",
    "                name = f'{target_feature}_{shift}_CATEGORIE_{stat}'\n",
    "                feat = f'{target_feature}_{shift}'\n",
    "                x_data[name] = x_data.groupby(gb_features)[feat].transform(stat)\n",
    "\n",
    "        new_feat_data = pd.concat([new_feat_data,x_data[new_features]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout des new features aux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train = new_feat_train.loc[train_cl.index]\n",
    "new_feat_test = new_feat_test.loc[test_cl.index] #Réindexage pour associer les new features aux bonnes lignes\n",
    "\n",
    "train_cl[new_features] = new_feat_train\n",
    "test_cl[new_features] = new_feat_test #Ajout des colonnes new features au dataset d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles par groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle INDUSTRY_GROUP 16 entraîné : 39290 données\n",
      "Modèle SECTOR 0 entraîné : 6304 données\n",
      "Modèle SECTOR 1 entraîné : 21264 données\n",
      "Modèle SECTOR 2 entraîné : 18967 données\n",
      "Modèle SECTOR 3 entraîné : 55473 données\n",
      "Modèle SECTOR 4 entraîné : 63519 données\n",
      "Modèle SECTOR 5 entraîné : 17295 données\n",
      "Modèle SECTOR 6 entraîné : 55122 données\n",
      "Modèle SECTOR 7 entraîné : 87903 données\n",
      "Modèle SECTOR 8 entraîné : 70843 données\n",
      "Modèle SECTOR 9 entraîné : 5555 données\n",
      "Modèle SECTOR 10 entraîné : 13295 données\n",
      "Modèle SECTOR 11 entraîné : 3054 données\n"
     ]
    }
   ],
   "source": [
    "models = [{} for ind_cat in range(len(categories)+1)]\n",
    "features = features_base + new_features\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    for ind_group,group in enumerate(model_labels[ind_cat]):\n",
    "        \n",
    "        x_train_cl = train_cl.copy()[train_cl[cat]==group]\n",
    "        y_train_cl = train_cl[target][train_cl[cat]==group]\n",
    "\n",
    "        model = RandomForestClassifier(**rf_params)\n",
    "        model.fit(x_train_cl[features], y_train_cl)\n",
    "        models[ind_cat][group] = model\n",
    "\n",
    "        print(f\"Modèle {cat} {group} entraîné : {len(x_train_cl)} données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle général si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_temp)>0:\n",
    "    \n",
    "    x_train_cl = train_cl.copy()\n",
    "    y_train_cl = train_cl[target]\n",
    "\n",
    "    model = RandomForestClassifier(**rf_params)\n",
    "    model.fit(x_train_cl[features], y_train_cl)\n",
    "    models[5]['general'] = model\n",
    "    print(f\"Modèle général entraîné : {len(x_train_cl)} données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions par groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17939 données prédites avec le modèle INDUSTRY_GROUP 16\n",
      "2177 données prédites avec le modèle SECTOR 0\n",
      "11844 données prédites avec le modèle SECTOR 1\n",
      "9176 données prédites avec le modèle SECTOR 2\n",
      "27312 données prédites avec le modèle SECTOR 3\n",
      "27951 données prédites avec le modèle SECTOR 4\n",
      "7977 données prédites avec le modèle SECTOR 5\n",
      "27706 données prédites avec le modèle SECTOR 6\n",
      "23248 données prédites avec le modèle SECTOR 7\n",
      "30092 données prédites avec le modèle SECTOR 8\n",
      "3358 données prédites avec le modèle SECTOR 9\n",
      "5733 données prédites avec le modèle SECTOR 10\n",
      "3916 données prédites avec le modèle SECTOR 11\n"
     ]
    }
   ],
   "source": [
    "test_temp = test_cl.copy()\n",
    "y_pred = pd.Series()\n",
    "\n",
    "for ind_cat,cat in enumerate(categories):\n",
    "    for ind_group,group in enumerate(model_labels[ind_cat]):\n",
    "        \n",
    "        x_test = test_temp.copy().loc[test_temp[cat]==group,:]\n",
    "        if len(x_test)>0:\n",
    "            \n",
    "            index = x_test.index\n",
    "            model = models[ind_cat][group]\n",
    "            y_pred = pd.concat([y_pred,pd.Series(model.predict(x_test[features]),index=x_test.index)])\n",
    "            print(f\"{len(x_test)} données prédites avec le modèle {cat} {group}\")\n",
    "\n",
    "            test_temp = test_temp[test_temp[cat]!=group] #On supprime les données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions avec le modèle général si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(test_temp)>0:\n",
    "    x_test = test_temp.copy()\n",
    "    index = x_test.index\n",
    "    model = models[5]['general']\n",
    "    \n",
    "    y_pred = pd.concat([y_pred,pd.Series(model.predict(x_test[features]),index=x_test.index)])\n",
    "    print(f\"{len(x_test)} données prédites avec le modèle général\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données prédites pour submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred[test_cl.index]\n",
    "y_pred.name = target\n",
    "# y_pred.to_csv('./nom_submit.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
